{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN 모델을 이용한 객체 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import torch\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습 마스크 R-CNN 로딩\n",
    "model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 다운로드\n",
    "!wget https://github.com/pytorch/hub/raw/master/images/dog.jpg -o dog.jpg\n",
    "!wget http://images.cocodataset.org/val2017/000000039769.jpg -o coco.jpg\n",
    "!wget https://ultralytics.com/images/bus.jpg -o bus.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 오픈\n",
    "from PIL import Image\n",
    "image = Image.open('bus.jpg').convert('RGB')\n",
    "\n",
    "# 이미지 전처리\n",
    "image = F.to_tensor(image) # 텐서변환\n",
    "image = image.unsqueeze(0) # 차원추가\n",
    "\n",
    "# 예측\n",
    "with torch.no_grad():\n",
    "    prediction = model(image)\n",
    "\n",
    "    boxes = prediction[0]['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import draw_bounding_boxes\n",
    "draw_bounding_boxes(image,boxes,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR 모델을 이용한 객체감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "# Load model directly\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 오픈\n",
    "image = Image.open('coco.jpg').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# 예측\n",
    "predictions = model(**inputs)\n",
    "\n",
    "# 바운딩 박스 좌표\n",
    "predictions['pred_boxes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR 파이프라인을 이용한 객체감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프 라인 로딩\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 오픈\n",
    "image = Image.open('coco.jpg').convert('RGB')\n",
    "\n",
    "pipe.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코코 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone\n",
    "\n",
    "dataset = fiftyone.zoo.load_zoo_dataset(\"coco-2017\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fiftyone.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"detections\", \"segmentations\"],\n",
    "    classes=[\"person\", \"car\"],\n",
    "    max_samples=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset in the FiftyOne App\n",
    "session = fiftyone.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO를 이용한 객체감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "with torch.no_grad():\n",
    "    prediction = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load a COCO-pretrained YOLOv8n model\n",
    "model= YOLO(\"yolov8n.pt\")\n",
    "# Display model information (optional)\n",
    "model.info()\n",
    "# Train the model on the COCO8 example dataset for 100 epochs\n",
    "results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)\n",
    "# Run inference with the YOLOv8n model on the '20.jpg' image\n",
    "results= model(\"https://ultralytics.com/images/bus.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny YOLO를 이용한 객체 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# 이미지 가져오기\n",
    "image = Image.open('coco.jpg').convert('RGB')\n",
    "# 예측\n",
    "\n",
    "# 이미지 전처리\n",
    "image = F.to_tensor(image) # 텐서변환\n",
    "image = image.unsqueeze(0) # 차원추가\n",
    "\n",
    "# 예측\n",
    "with torch.no_grad():\n",
    "    prediction = model(image)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 가져오기\n",
    "image = Image.open('coco.jpg').convert('RGB')\n",
    "\n",
    "# 전처리기, 객체탐지기 설정\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "\n",
    "# 전처리 및 예측\n",
    "inputs = processor(images=image, return_tensors=\"pt\") #전처리\n",
    "outputs = model(**inputs) #예측\n",
    "\n",
    "# 출력값 포매팅\n",
    "target_sizes = torch.tensor([image.size[::-1]]) # 높이, 폭인 텐서로 변환\n",
    "results = processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0] # 사이즈 변환\n",
    "\n",
    "# 객체 감지 결과 반복\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()] # 소수 둘째자리 반올림\n",
    "    print(f\"Detected {model.config.id2label[label.item()]} with confidence \")\n",
    "    print(f\"{round(score.item(), 3)} at location {box}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roboflow 이용해서 데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"5vRdkgspDTVwQk0t4A41\")\n",
    "project = rf.workspace(\"ssong-w9vsb\").project(\"hard-hat-sample-oocvp\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
